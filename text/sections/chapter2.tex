\chapter{First hitting time regression models}

\section{Survival analysis and time-to-event models}\label{sec:survival}
In many fields, it is interesting to consider the lifetime of some entity. A lifetime ends when an event occurs. We are usually interested in inferring things about this lifetime, and what it depends upon. In medical fields, this is called survival analysis, while in engineering it is called reliability analysis. In the former case, we consider the lifetime of patients or the length of a hospital stay after some treatment. In the latter, we consider, e.g., the time before a component of a system breaks and must be replaced. Let the time-to-event $T$ be a continuous non-negative random variable following cumulative distribution function $F(t)$, such that
\begin{equation*}%\label{eq:pdf}
    F(t)=\Pr(T<t)
\end{equation*}
is the probability of the event having happened before time $t$. We define the survival function $S(t)$ to be the converse, namely
\begin{equation*}%\label
    S(t)=1-F(t),
\end{equation*}
and it hence denotes the probability that the event has not yet happened at time $t$. If the cumulative distribution function is differentiable, we define the probability density function of $T$ to be $f(t)$. It is then the probability that the event happens at time $t$. Another important thing to consider is the hazard function $h(t)$. Somewhat informally, it denotes the probability of the event happening at some time $t$, assuming it has not happened yet. More formally, it is the limit of the conditional probability that the event will occur in a small interval $[t,t+\Delta t)$,
\begin{equation*}%\label{eq:hazard}
h(t)=\lim_{\Delta t\to 0}\frac{\Pr(t\leq T<t+\Delta t|T\geq t)}{\Delta t}.
\end{equation*}

\subsection{Data structures}\label{sec:surv-data}
Assume we observe $\ti$, $i=1,\dotsc,n$ independent and identically distributed (\textit{iid}) observations from distribution $f$. For a single individual event $i$, we might observe the following. The time $\ti$ of the observation. Covariates $\xi$ describing the individual. An indicator $\di$ of whether the individual event has occurred ($\di = 1$) or not ($\di = 0$). We are interested in setting up the sample likelihood. If the event has occurred, $\di=1$, the single individual $i$ contributes to the sample likelihood
\begin{equation*}
    f(\ti|\xi)=f(\ti|\xi)^{\di},
\end{equation*}
and if the event has not occurred, $\di=0\rightarrow1-\di=1$, then it contributes
\begin{equation*}
    S(\ti|\xi)=S(\ti|\xi)^{1-\di}.
\end{equation*}
Hence, the sample likelihood becomes
\begin{equation}\label{eq:surv-lik}
    L(\btheta|\x_{(1)},\ldots,\x_{(n)})=\prod_{i=1}^n f(\ti|\xi,\btheta)^{\di} S(\ti|\xi,\btheta)^{1-\di}.
\end{equation}
\subsection{Proportional hazards}
The most used method for doing regression on survival data is the Cox proportional hazards (PH) regression. It is based on an assumption that is often called the PH property or the PH assumption, namely that
\begin{equation}
    h(t|x)=h_0(t)g(\x),
\end{equation}
where $h_0(t)$ is a baseline hazard function. \todo[inline]{more about baseline hazard?} This property states that at any two time points $t_1$ and $t_2$, the ratio between the hazard functions of any two $\x_1$ and $\x_2$ will be the same:
\begin{equation}
    \frac{h(t_1|x_1)}{h(t_1|x_2)}=\frac{h(t_2|x_1)}{h(t_2|x_2)}
\end{equation}
This is a strong assumption to make, and it will rarely be the case in practice (\cite{lee2010})\todo{how to rephrase?}. However, many times Cox regression will work well in practice. \todo{really? or argue why!}

\section{The First Hitting Time (FHT) Model}\label{sec:fht}
Time-to-event data analysis in biomedical sciences is dominated by Cox regression, which is a semiparametric proportional hazards model, and which directly estimates the hazard rate (\cite{stogiannis-2013}). A class of parametric models which has gotten increasingly more attention recently is the first hitting time (FHT) model, originally developed by G.A. Whitmore in 1986 (\cite{whitmore1986}, \cite{leewhitmore2006}). The idea of the FHT model is that we might suppose that for each individual there is some underlying stochastic process, which, when it reaches some threshold (or, more generally, an absorbing state), triggers the event, at which point the lifetime ends. The time-to-event, or lifetime, is then the time it takes for the process to reach this state. This is an attractive model because it models the process instead of the hazard rate (\cite{aalengjessing2001}), and it is conceptually appealing, since an event usually does not happen for no reason, but it happens due to e.g. a health status becoming sufficiently bad. We now descibe the key components in the FHT model. There is a parent stochastic process $\{Y(t)\}$, $Y\in\setY$, time $t$ non-negative, $t\in\setT$, with $t\geq0$. The process has initial value $Y(0)=y_0$. There is a boundary set $\setB\subset\setT$, and by definition $y_0\notin\setB$, since the event has not happened at time $t=0$. The boundary set $\setB$ is at times referred to as a boundary, barrier, or threshold, all of which are synonymous. The preferred term varies with interpretation and use.
The choice of process is flexible. It might have continuous or discrete sample paths. We define the first hitting time $S$ to be the first time $t$ that the process $Y$ reaches the absorbing state $B$,
\begin{equation}
    S=\inf\{t\colon Y(t)\in\setB\}.
\end{equation}
Note that it is quite possible that the process does not reach an absorbing state, and so that $P(S<\infty)<1$. The FHT model does not require the PH assumption, and is hence more flexible. In fact, the PH model may be obtained by constructing the first hitting time model in a specific way (\cite{lee2010}). Different choices for the process $Y$ lead to different kinds of distributions for the first hitting time. We now look at a common choice of the process.

\subsection{Wiener process}\label{sec:wiener}
The Wiener process, also known as the standard Brownian motion process, is a process which is continuous in time and space. The Wiener process is a fairly simple process: It has three parameters. The drift $\mu$, the variance $\sigma^2$, and the initial value $Y(0)=y_0$. It has independent increments, such that $Y(t_2)-Y(t_1)$ and $Y(t_4)-Y(t_3)$ are independent for any disjoint intervals $(t_1,t_2)$ and $(t_3,t_4)$. Each increment is normally distributed and with both the mean and the standard deviation proportional to the length of the interval, i.e., for any interval $(t_1, t_2)$,
\begin{equation}
    Y(t_2)-Y(t_1)\sim N(\mu(t_2-t_1), \sigma^2(t_2-t_1)).
\end{equation}
If we let the process $Y$ in the FHT model, we will typically choose the boundary $\setB$ to be $\setB=(-\infty,0]$, i.e., the event is triggered when $Y\leq0$. Accordingly, we then also assume that the initial level $y_0$ is positive. This is a very conceptually appealing model, because it assumes that individuals might have different initial levels, and that also the drift might be different between individuals. It is also attractive because it has closed-form probability and cumulative density functions, and its likelihood is computationally simple. There are no restrictions on the movements of the process, meaning, it is non-monotonic. If we do want a monotonic restriction on the movement of the process, we may use a gamma process.

\subsection{Other processes}
The gamma process is suitable for modelling a process which we would require to be monotonic, typically a physical degradation, i.e. where the damage cannot mend itself, unlike a patient's health. The first hitting time that arises from the gamma process is an inverse gamma first hitting time distribution (\cite[503]{leewhitmore2006}). Other choices of processes include Markov chain state models, the Bernoulli process, and the Ornstein-Uhlenbeck process. We will however in this thesis use the Wiener process, as it is simple but as flexible as we need.

\section{First hitting time regression based on underlying Wiener process}
The first hitting time of the Wiener process (section \ref{sec:wiener}) follows an inverse Gaussian distribution (derivation in \cite[23-29]{chhikara1988}\todo{also derive more clearly in appendix?}):
\begin{equation}
\label{eq:fht-ig}
    f(t|y_0,\mu,\sigma^2)=\frac{y_0}{\sqrt{2\pi\sigma^2t^3}}\exp\left[-\frac{(y_0+\mu t)^2}{2\sigma^2t}\right]
\end{equation}
If the drift $\mu$ is positive, then it is not certain that the process will reach 0, so in this case it is an improper pdf. If the measurement of the process is latent, then it can be given an arbitrary measurement unit. Thus, we may fix one parameter. We choose to set the variance to unity, i.e., $\sigma^2=1$ (\cite{leewhitmore2006}). While $\mu$ and $y_0$ have simple interpretations in terms of the underlying process, they do not in terms of the lifetime distribution. The mean lifetime is $\frac{y_0}{|\mu|}$, and the variance is $\frac{y_0}{|\mu|^3}$. (\cite[62]{caroni2017}.)

The cumulative distribution function of the FHT is (from \cite[7]{threg})
\begin{equation}\label{eq:cumulative}
    F(t|\mu,\sigma^2,y_0)=\Phi\sqb*{-\frac{(y_0+\mu t)}{\sqrt{\sigma^2t}}}+\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\sqb*{\frac{\mu t-y_0}{\sqrt{\sigma^2t}}},
\end{equation}
where $\Phi(x)$ is the cumulative of the standard normal, i.e.,
\begin{equation}
    \Phi(x)=\int_{-\infty}^x\exp(-y^2/2)/\sqrt{2\pi}\dy.
\end{equation}

\subsection{Regression}
We may introduce effects from covariates by allowing $\mu$ and $y_0$ to depend on covariates $\x$. Suitable models are
\begin{align}\label{eq:coeffs}
\begin{split}
    \mu=\bbeta^\T\xÂ \\
    \ln y_0=\bgamma^\T\z
\end{split}
\end{align}
where $\bbeta$ and $\bgamma$ are vectors of regression coefficients, and where we use the identity and the logarithm as link functions, respectively. Note that we may let $\x$ and $\z$ share none, some, or all elements.

\section{Likelihood}\label{sec:lik}
In section \ref{sec:survival}, we stated the likelihood of lifetime regression models in \eqref{eq:surv-lik}. For an inverse gaussian FHT this then becomes (inserting \eqref{eq:fht-ig} and \eqref{eq:cumulative} into \eqref{eq:surv-lik}, and since $S(t)=1-F(t)$)
\begin{align}\label{eq:fht-lik}
\begin{split}
L(\btheta)&=\p*{\frac{y_0}{\sqrt{2\pi\sigma^2t^3}}\exp\left[-\frac{(y_0+\mu t)^2}{2\sigma^2t}\right]}^{\delta_i}\\
&\times\sqb*{1-\Phi\p*{-\frac{y_0+\mu t}{\sqrt{\sigma^2t}}}-\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\p*{\frac{\mu t-y_0}{\sqrt{\sigma^2t}}}}^{1-\delta_i}
\end{split}
\end{align}
We can now substitute the covariates in \eqref{eq:coeffs} into this.

\subsection{Optimization}
Until now, mainly numerical maximum likelihood methods have been used to find optimal parameters, via direct maximization of the likelihood. Finding a closed-form solution for the maximum likelihood is not possible. It is only feasible to do numerical optimization of the maximum likelihood in the low-dimensional case, since it will optimize the entire parameter space at once. Therefore it is necessary to develop methods which can deal with high-dimensional cases. That is what we intend to do in the main part of the thesis. For our purposes, we need to differentiate the logarithm with respect to the parameters $\mu$ and $y_0$. Note first that $1-\Phi(-x)=\Phi(x)$, where $\Phi(x)$ is the cumulative distribution function for the standard normal distribution. Secondly, since the logarithm is monotone, it preserves optimality, and hence we can take the logarithm of \eqref{eq:fht-lik}, and we get
\begin{align}\label{eq:loglik}
\begin{split}
    l(\btheta)&=\sum_{i=1}^n\di\p*{\ln y_0-\frac{1}{2}\ln\p*{2\pi\sigma^2\ti^3}-\frac{\p*{y_0+\mu\ti}^2}{2\sigma^2\ti}} \\
    &+
    (1-\di)\ln\p*{\Phi\p*{\frac{\mu\ti+y_0}{\sqrt{\sigma^2\ti}}}-\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\p*{\frac{\mu\ti-y_0}{\sqrt{\sigma^2\ti}}}}
\end{split}
\end{align}
See the appendix \ref{appendix} for the full derivation.