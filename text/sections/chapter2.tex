\chapter{First hitting time regression models}

\section{Survival analysis and time-to-event models}\label{sec:survival}
Lifetimes and time-to-event data are of interest in many applications. Oncologists, doctors who study cancer, are interested in how quickly patients die after cancer has been discovered. Sociologists might be interested in the duration of marriages before divorce. We say that a lifetime $T$ ends when an event occurs. In the previous examples, the events in question are death and divorce, say. We are usually interested in making inference about this lifetime, and in particular what factors it depends upon. In biomedical fields, this is known as survival analysis, while in engineering it is called reliability analysis. These are much studied fields. The main part of our thesis is applicable in both areas. In the former case, we may consider the time before a component of a system breaks and must be replaced. Let the lifetime or time-to-event $T$ be a continuous non-negative random variable following a cumulative distribution function $F(t)$, such that
\begin{equation*}%\label{eq:pdf}
    F(t)=\Pr(T<t)
\end{equation*}
is the probability of the event having happened before time $t$. We define the survival function $S(t)$ to be the converse, namely
\begin{equation*}%\label
    S(t)=1-F(t).
\end{equation*}
Hence, $S(t)$ denotes the probability that the event has not yet happened at time $t$. If the cumulative distribution function is differentiable, we define the probability density function of $T$ to be $f(t)$. Another much studied property of lifetime distributions is the hazard function $h(t)$. Somewhat informally, it denotes the probability of the event happening at some time $t$, assuming it has not happened yet. More formally, it is the limit of the conditional probability that the event will occur in a small interval $[t,t+\Delta t)$, conditional on the event not having happened yet,
\begin{equation*}%\label{eq:hazard}
    h(t)=\lim_{\Delta t\to 0}\frac{\Pr(t\leq T<t+\Delta t|T\geq t)}{\Delta t}=\frac{f(t)}{F(t)}.
\end{equation*}
\subsection{Censored data}
In theory, a lifetime will always end. In the real world, however, we are constrained with finite time. Thus, when we observe lifetime data, it is not necessarily the case that the lifetime has ended yet. For example, some cancer patients survive, and die of old age. Similarly, some marriages do not end in divorce. In these cases, it is likely that the lifetime has not ended at the time we stop observing data. Here we cannot say anything about the lifetime itself. We can only say that this lifetime lasted at least until now. We call these observations censored observations. Specifically, these are right-censored observations, since they are censored at the right end of the time scale.
\subsection{Data structures}\label{sec:surv-data}
Assume we observe $\ti$, $i=1,\dotsc,n$ independent and identically distributed (\textit{iid}) observations from a random variable with density distribution $f$. For a single individual event $i$, we might observe the following. The time $\ti$ of the observation. Covariates $\xi$ describing the individual. An indicator $\di$ of whether the individual event has occurred ($\di = 1$) or not ($\di = 0$). The latter events, corresponding to $\di=0$, are censored. We are interested in setting up the likelihood, where we incorporate the covariates $\xi$ into a parameter $\btheta$. If the event has occurred, the indicator $\di$ is 1. We can then use the information about the lifetime distribution, such that the single individual $i$ contributes
\begin{equation}\label{eq:f}
    f(\ti|\xi)
\end{equation}
to the likelihood. If the event has not (yet) occurred, the observation is censored, and $\di$ is 0. Since we do not have the actual lifetime, we cannot use the lifetime distribution. We must use the survival distribution. As such, this observation contributes
\begin{equation}\label{eq:S}
    S(\ti|\xi)
\end{equation}
to the likelihood. Obviously, since an observation can only be either censored or not censored at the same time, $\di$ is either 0 or 1. If the event has occurred, $\di$ is 1, and then $1-\di$ is 0. Similarly, if the event has not occurred and the event is censored, then $\di$
 is 0, and then $1-\di$ is 1. This allows us to take the product of \eqref{eq:f} and \eqref{eq:S} where we take these to the power of $\di$ and $1-\di$, respectively, so that a single observation makes a contribution of
\begin{equation*}
    f(\ti|\xi)^{\di}S(\ti|\xi)^{1-\di}
\end{equation*}
to the likelihood. Since we assumed the observations were independent, the likelihood of the observed sample as a whole is the product of the single likelihoods. The likelihood becomes
\begin{equation}\label{eq:surv-lik}
    L(\btheta|\x_{(1)},\ldots,\x_{(n)})=\prod_{i=1}^n f(\ti|\xi,\btheta)^{\di} S(\ti|\xi,\btheta)^{1-\di}.
\end{equation}
\subsection{Proportional hazards}
The most used method for doing regression on survival data is the Cox proportional hazards (PH) regression. It is based on an assumption that is often called the PH property or the PH assumption, namely that
\begin{equation}
    h(t|x)=h_0(t)g(\x),
\end{equation}
where $h_0(t)$ is a baseline hazard function, which is common for all individuals. This means that at any two time points $t_1$ and $t_2$, the ratio between the hazard functions of any two $\x_1$ and $\x_2$ will be the same:
\begin{equation}
    \frac{h(t_1|x_1)}{h(t_1|x_2)}=\frac{h(t_2|x_1)}{h(t_2|x_2)}
\end{equation}
This is a strong assumption to make, and it will not always be the case in practice \citep{lee2010}. Therefore there is a need for more flexible methods in survival analysis, where this assumption is not necessary.

\section{The First Hitting Time (FHT) Model}\label{sec:fht}
Time-to-event data analysis in biomedical sciences is dominated by Cox regression, which is a semiparametric proportional hazards model, and which directly estimates the hazard rate \citep{stogiannis-2013}. A class of parametric models which has got increasingly more attention recently is the first hitting time (FHT) model, originally developed by \citeauthor{whitmore1986} in \citeyear{whitmore1986} \citep{whitmore1986,leewhitmore2006}. The FHT model has been applied successfully to different kinds of data, especially in biomedial sciences. Examples include modelling lung cancer risk in railroad workers \citep{leewhitmore2004}, ... In an FHT model, the health of an individual is modelled as a stochastic process, which, when it reaches some threshold (or, more generally, an absorbing state), triggers the event, at which point the lifetime ends. The time-to-event, or lifetime, becomes the time it takes for the process to reach this state. This is an attractive model because it models the process instead of the hazard rate \citep{aalengjessing2001}. It is also conceptually appealing, because it makes sense to imagine that there is some process governing when events happen, such that for two living individuals, they might have different distances, so to speak, away from death. %\todo{hmm ... is this good enough?}
We now descibe the key components in the FHT model. There is a parent stochastic process $\{Y(t)\}$, $Y\in\setY$, time $t$ non-negative, $t\in\setT$. The process has initial value $Y(0)=y_0$. There is a boundary set $\setB\subset\setT$, which is at times referred to as a boundary, barrier, or threshold, all of which are synonymous. The preferred term varies with which interpretation we want to use and what connotations we want to evoke.
The choice of process is flexible. It might have continuous or discrete sample paths. We define the first hitting time $S$ to be the first time $t$ that the process $Y$ reaches the absorbing state $B\in\setB$,
\begin{equation}
    S=\inf\{t\colon Y(t)\in\setB\}.
\end{equation}
Note that by definition $y_0\notin\setB$, since the event has not yet happened at time $t=0$. Note also that it is quite possible that the process does not reach an absorbing state, and so that $P(S<\infty)<1$. The FHT model does not require the PH assumption, and is hence more flexible. In fact, the PH model may be obtained by constructing the first hitting time model in a specific way \citep{lee2010}. Different choices for the process $Y$ lead to different kinds of distributions for the first hitting time. We now look at some common choices for the process.

\subsection{Wiener process}\label{sec:wiener}
The Wiener process, also known as the standard Brownian motion process, is a process which is continuous in time and space. It is so far the most commonly used process in FHT literature. The Wiener process is a fairly simple process: It has three parameters, the drift $\mu$, the variance $\sigma^2$, and the initial value $Y(0)=y_0$. It has independent increments, such that $Y(t_2)-Y(t_1)$ and $Y(t_4)-Y(t_3)$ are independent for any disjoint intervals $(t_1,t_2)$ and $(t_3,t_4)$. Each increment is normally distributed and with both the mean and the standard deviation proportional to the length of the interval, i.e., for any interval $(t_1, t_2)$,
\begin{equation}
    Y(t_2)-Y(t_1)\sim N(\mu(t_2-t_1), \sigma^2(t_2-t_1)).
\end{equation}
If we consider $Y$ to be a Wiener process in the FHT model, we will typically choose the boundary $\setB$ to be $\setB=(-\infty,0]$, i.e., the event is triggered when $Y\leq0$. Accordingly, we then also assume that the initial level $y_0$ is positive. This is a very conceptually appealing model, because it assumes that individuals might have different initial levels, and that also the drift might be different between individuals. It is also attractive because it has closed-form probability and cumulative density functions, and its likelihood is computationally simple. There are no restrictions on the movements of the process, meaning, it is non-monotonic. If we do want a monotonic restriction on the movement of the process, we may use a gamma process.

\subsection{Other processes}
The gamma process is suitable for modelling a process which we would require to be monotonic, typically a physical degradation, i.e. where the damage cannot mend itself, unlike a patient's health. The first hitting time that arises from the gamma process is an inverse gamma first hitting time distribution \citep{leewhitmore2006}. Other choices of processes include Markov chain state models, the Bernoulli process, and the Ornstein-Uhlenbeck process. For a complete review, see \cite{leewhitmore2006}. Due to its simplicity and flexibility, we will in thesis focus on the Wiener process as the choice of process in the FHT model. However, large parts of our results can easily be extended for other processes. For brevity, we will in the sequel say ``the FHT'' when we in fact mean the FHT with the Wiener process.

\section{First hitting time regression based on underlying Wiener process}
It can be shown that the first hitting time of the Wiener process follows an inverse Gaussian distribution \citep{chhikara1988},
\begin{equation}
\label{eq:fht-ig}
    f(t|y_0,\mu,\sigma^2)=\frac{y_0}{\sqrt{2\pi\sigma^2t^3}}\exp\left[-\frac{(y_0+\mu t)^2}{2\sigma^2t}\right].
\end{equation}
See Appendix \todo{TO DO!} for the mathematical derivation. If the drift $\mu$ is positive, then it is not certain that the process will reach 0, so in this case it is an improper pdf. In most cases, $y$ is not measured directly. If that is the case, then the scale of $y$ is arbitrary. Thus, we may fix one parameter in the distribution. As per convention we choose to set the variance to unity, i.e., $\sigma^2=1$ \citep{leewhitmore2006,caroni2017}. While $\mu$ and $y_0$ have simple interpretations in terms of the underlying process, they do not in terms of the lifetime distribution. The mean lifetime is $\frac{y_0}{|\mu|}$, and its variance is $\frac{y_0}{|\mu|^3}$ \citep{caroni2017}. This 

The cumulative distribution function of the FHT is \citep{threg}
\begin{equation}\label{eq:cumulative}
    F(t|\mu,\sigma^2,y_0)=\Phi\sqb*{-\frac{(\mu t+y_0)}{\sqrt{\sigma^2t}}}+\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\sqb*{\frac{\mu t-y_0}{\sqrt{\sigma^2t}}},
\end{equation}
where $\Phi(x)$ is the cumulative distribution function of the standard normal, i.e.,
\begin{equation}
    \Phi(x)=\int_{-\infty}^x\exp(-y^2/2)/\sqrt{2\pi}\dy.
\end{equation}
The survival function $S(t)$ is
\begin{align}\label{eq:survival}
\begin{split}
S(t)&=1-\Phi\sqb*{-\frac{(\mu t+y_0)}{\sqrt{\sigma^2t}}}-\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\sqb*{\frac{\mu t-y_0}{\sqrt{\sigma^2t}}}\\
&=\Phi\sqb*{\frac{\mu t+y_0}{\sqrt{\sigma^2t}}}-\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\sqb*{\frac{\mu t-y_0}{\sqrt{\sigma^2t}}}.
\end{split}
\end{align}
In the last step we use the fact that $1-\Phi(-x)=\Phi(x)$, since the standard normal distribution is symmetric around 0.

\subsection{Regression}
We may introduce effects from covariates by allowing $\mu$ and $y_0$ to depend on covariates $\x$ and $\z$. A simple and much used model is to use the identity and the logarithm link function for the drift $\mu$ and the initial level $y_0$, respectively.
\begin{align}\label{eq:coeffs}
\begin{split}
    \mu=\bbeta^\T\x \\
    \ln y_0=\bgamma^\T\z
\end{split}
\end{align}
$\bbeta$ and $\bgamma$ are vectors of regression coefficients. Note that we may let $\x$ and $\z$ share none, some, or all elements.

\section{Likelihood}\label{sec:lik}
In formula \eqref{eq:surv-lik}, we reported the likelihood of lifetime regression models in its most general formulation. For an inverse Gaussian FHT this then becomes (inserting \eqref{eq:fht-ig} and \eqref{eq:survival} into \eqref{eq:surv-lik})
\begin{align}\label{eq:fht-lik}
\begin{split}
L(\btheta)&=\p*{\frac{y_0}{\sqrt{2\pi\sigma^2t^3}}\exp\left[-\frac{(y_0+\mu t)^2}{2\sigma^2t}\right]}^{\delta_i}\\
&\times\sqb*{\Phi\p*{\frac{\mu_t+y_0}{\sqrt{\sigma^2t}}}-\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\p*{\frac{\mu t-y_0}{\sqrt{\sigma^2t}}}}^{1-\delta_i}
\end{split}
\end{align}
We can now substitute the covariates in \eqref{eq:coeffs} into this.
%\todo[inline]{This can be expanded a lot more!}

\subsection{Optimization}
%\todo{not really!!}
Until now, mainly numerical maximum likelihood methods have been used to find optimal parameters, via direct maximization of the likelihood. Finding a closed-form solution for the maximum likelihood is not possible. It is only feasible to do numerical optimization of the maximum likelihood in the low-dimensional case, since it will optimize the entire parameter space at once. Therefore it is necessary to develop methods which can deal with high-dimensional cases. That is what we intend to do in the main part of the thesis. For our purposes, we need to differentiate the logarithm with respect to the parameters $\mu$ and $y_0$. Since the logarithm is monotone, it preserves optimality, and hence we can take the logarithm of \eqref{eq:fht-lik}, and we get
\begin{align}\label{eq:loglik}
\begin{split}
    l(\btheta)&=\sum_{i=1}^n\di\p*{\ln y_0-\frac{1}{2}\ln\p*{2\pi\sigma^2\ti^3}-\frac{\p*{y_0+\mu\ti}^2}{2\sigma^2\ti}} \\
    &+
    (1-\di)\ln\p*{\Phi\p*{\frac{\mu\ti+y_0}{\sqrt{\sigma^2\ti}}}-\exp\p*{-\frac{2y_0\mu}{\sigma^2}}\Phi\p*{\frac{\mu\ti-y_0}{\sqrt{\sigma^2\ti}}}}
\end{split}
\end{align}
See the appendix \ref{appendix} for the full derivation.